{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c16de3-8a53-4892-ba92-918f0ea8897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U psycopg2-binary\n",
    "# !pip install -U jsondiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb42df7c-c6c4-441e-9ef8-6bae81375979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import jsondiff\n",
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "from datetime import date, datetime\n",
    "import csv\n",
    "\n",
    "with open('./config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "db_file = './sierra_patron_data.db'\n",
    "\n",
    "class SQLiteConnection:\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "    with SQLiteConnection('your_database_path.sqlite') as conn:\n",
    "        # Your database operations here\n",
    "    \"\"\"\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_diff(new_json, old_json):\n",
    "        return str(\n",
    "            jsondiff.diff(\n",
    "                new_json, \n",
    "                old_json, \n",
    "                load=True, \n",
    "                dump=True, \n",
    "                marshal=True, \n",
    "                syntax='explicit'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        self.conn.create_function('json_diff', 2, self.compute_diff)\n",
    "        return self.conn\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sql = \"\"\"\\\n",
    "        PRAGMA analysis_limit=2000;\n",
    "        PRAGMA optimize;\n",
    "        \"\"\"\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.executescript(sql)\n",
    "        \n",
    "        self.conn.close()\n",
    "\n",
    "# some test suggestions\n",
    "# \n",
    "# import unittest\n",
    "# import sqlite3\n",
    "\n",
    "# class TestSQLiteConnection(unittest.TestCase):\n",
    "\n",
    "#     TEST_DB_PATH = ':memory:'  # We'll use an in-memory database for testing\n",
    "\n",
    "#     def test_connection_established(self):\n",
    "#         with SQLiteConnection(self.TEST_DB_PATH) as conn:\n",
    "#             self.assertIsInstance(conn, sqlite3.Connection)\n",
    "\n",
    "#     def test_json_diff_function_registered(self):\n",
    "#         with SQLiteConnection(self.TEST_DB_PATH) as conn:\n",
    "#             cursor = conn.cursor()\n",
    "#             # We'll use a simple test for the json_diff function here\n",
    "#             result = cursor.execute(\"SELECT json_diff('old', 'new')\").fetchone()\n",
    "#             self.assertEqual(result[0], \"old -> new\")\n",
    "\n",
    "#     def test_connection_closed_after_exit(self):\n",
    "#         with SQLiteConnection(self.TEST_DB_PATH) as conn:\n",
    "#             pass  # Exiting the with block\n",
    "#         self.assertTrue(conn.in_transaction is None)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main()\n",
    "\n",
    "# if not os.path.isfile(db_file):\n",
    "#     print('not exists')\n",
    "#     # start searching from timestamp 0\n",
    "#     latest_update = datetime.fromtimestamp(0).date().isoformat()\n",
    "# else:\n",
    "#     # query the sqlite db for the last update date\n",
    "#     pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c3c594-3035-4443-bda2-e88b60a262a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\\\n",
    "PRAGMA journal_mode=WAL;\n",
    "PRAGMA cache_size = 10000;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS patrons (\n",
    "    patron_record_id INTEGER PRIMARY KEY,\n",
    "    patron_record_num INTEGER,\n",
    "    campus_code TEXT,\n",
    "    barcode1 TEXT,\n",
    "    home_library_code TEXT,\n",
    "    ptype_code INTEGER,\n",
    "    create_date DATE,\n",
    "    delete_date DATE,\n",
    "    update_date DATE,\n",
    "    expire_date DATE,\n",
    "    active_date DATE,\n",
    "    claims_returned_total INTEGER,\n",
    "    owed_amt_cents INTEGER,\n",
    "    mblock_code TEXT,\n",
    "    highest_level_overdue_num INTEGER,\n",
    "    num_revisions INTEGER\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS patron_address_json (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    patron_record_id INTEGER UNIQUE,\n",
    "    json_data TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (patron_record_id) REFERENCES patrons(patron_record_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS identifiers_json (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    patron_record_id INTEGER UNIQUE,\n",
    "    json_data TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (patron_record_id) REFERENCES patrons(patron_record_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS phone_numbers_json (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    patron_record_id INTEGER UNIQUE,\n",
    "    json_data TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (patron_record_id) REFERENCES patrons(patron_record_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS emails_json (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    patron_record_id INTEGER UNIQUE,\n",
    "    json_data TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (patron_record_id) REFERENCES patrons(patron_record_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS json_changes (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    json_table_name TEXT,\n",
    "    patron_record_id INTEGER,\n",
    "    diff TEXT,\n",
    "    change_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "\n",
    "CREATE TRIGGER IF NOT EXISTS compute_address_diff\n",
    "AFTER UPDATE ON patron_address_json\n",
    "FOR EACH ROW\n",
    "WHEN OLD.json_data != NEW.json_data\n",
    "BEGIN\n",
    "    INSERT INTO json_changes (json_table_name, patron_record_id, diff)\n",
    "    VALUES ('patron_address_json', NEW.patron_record_id, json_diff(NEW.json_data, OLD.json_data));\n",
    "END;\n",
    "\n",
    "\n",
    "CREATE TRIGGER IF NOT EXISTS compute_identifiers_diff\n",
    "AFTER UPDATE ON identifiers_json\n",
    "FOR EACH ROW\n",
    "WHEN OLD.json_data != NEW.json_data\n",
    "BEGIN\n",
    "    INSERT INTO json_changes (json_table_name, json_table_id, diff)\n",
    "    VALUES ('identifiers_json', NEW.patron_record_id, json_diff(NEW.json_data, OLD.json_data));\n",
    "END;\n",
    "\n",
    "\n",
    "CREATE TRIGGER IF NOT EXISTS compute_phone_numbers_diff\n",
    "AFTER UPDATE ON phone_numbers_json\n",
    "FOR EACH ROW\n",
    "WHEN OLD.json_data != NEW.json_data\n",
    "BEGIN\n",
    "    INSERT INTO json_changes (json_table_name, json_table_id, diff)\n",
    "    VALUES ('phone_numbers_json', NEW.patron_record_id, json_diff(NEW.json_data, OLD.json_data ));\n",
    "END;\n",
    "\n",
    "\n",
    "CREATE TRIGGER IF NOT EXISTS compute_emails_diff\n",
    "AFTER UPDATE ON emails_json\n",
    "FOR EACH ROW\n",
    "WHEN OLD.json_data != NEW.json_data\n",
    "BEGIN\n",
    "    INSERT INTO json_changes (json_table_name, json_table_id, diff)\n",
    "    VALUES ('emails_json', NEW.patron_record_id, json_diff(NEW.json_data, OLD.json_data));\n",
    "END;\n",
    "\n",
    "ANALYZE;\n",
    "\"\"\"\n",
    "\n",
    "with SQLiteConnection(db_file) as con:\n",
    "    cursor = con.cursor()\n",
    "    cursor.executescript(sql)\n",
    "\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9074583-aab1-48ef-8292-2f9a488dd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_patron_insert = \"\"\"\\\n",
    "INSERT INTO patrons (\n",
    "    patron_record_id, patron_record_num, campus_code, barcode1, home_library_code,\n",
    "    ptype_code, create_date, delete_date, update_date, expire_date, active_date,\n",
    "    claims_returned_total, owed_amt_cents, mblock_code, highest_level_overdue_num, num_revisions\n",
    ") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "ON CONFLICT(patron_record_id) DO UPDATE SET\n",
    "    patron_record_num = excluded.patron_record_num,\n",
    "    campus_code = excluded.campus_code,\n",
    "    barcode1 = excluded.barcode1,\n",
    "    home_library_code = excluded.home_library_code,\n",
    "    ptype_code = excluded.ptype_code,\n",
    "    create_date = excluded.create_date,\n",
    "    delete_date = excluded.delete_date,\n",
    "    update_date = excluded.update_date,\n",
    "    expire_date = excluded.expire_date,\n",
    "    active_date = excluded.active_date,\n",
    "    claims_returned_total = excluded.claims_returned_total,\n",
    "    owed_amt_cents = excluded.owed_amt_cents,\n",
    "    mblock_code = excluded.mblock_code,\n",
    "    highest_level_overdue_num = excluded.highest_level_overdue_num,\n",
    "    num_revisions = excluded.num_revisions;\n",
    "\"\"\"\n",
    "\n",
    "sql_address_json_insert = \"\"\"\\\n",
    "INSERT INTO patron_address_json (\n",
    "    patron_record_id, json_data\n",
    ") VALUES (?, ?)\n",
    "ON CONFLICT(patron_record_id) DO UPDATE SET\n",
    "    json_data = excluded.json_data\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "sql_identifiers_json_insert = \"\"\"\\\n",
    "INSERT INTO identifiers_json (patron_record_id, json_data) VALUES (?, ?);\n",
    "\"\"\"\n",
    "\n",
    "sql_phone_numbers_json_insert = \"\"\"\\\n",
    "INSERT INTO phone_numbers_json (patron_record_id, json_data) VALUES (?, ?);\n",
    "\"\"\"\n",
    "\n",
    "sql_emails_json_insert = \"\"\"\\\n",
    "INSERT INTO emails_json (patron_record_id, json_data) VALUES (?, ?);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1103b0c-3646-41de-b428-5a44e2884ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-10 08:22:46 \n",
      "\n",
      "...................................done.  35\n"
     ]
    }
   ],
   "source": [
    "# connect to both the sierra db, and the local sqlite db\n",
    "with psycopg2.connect(dsn=config['dsn']) as con, \\\n",
    "SQLiteConnection(db_file) as con_sqlite:\n",
    "        \n",
    "    cursor = con.cursor(name=\"named_cursor\")\n",
    "    cursor_sqlite = con_sqlite.cursor()\n",
    "\n",
    "    # TODO .... query the local db or preserve a target a date with more precision than just the \"date\"\n",
    "    # \n",
    "    # get the latest update from the sqlite table .. or default to the earlest date possible\n",
    "    latest_update = datetime.fromtimestamp(0).date().isoformat()\n",
    "\n",
    "    sql = \"\"\"\\\n",
    "    SELECT\n",
    "    \tdatetime(\n",
    "    \t\tmax(json_changes.change_timestamp),   -- last record change detected\n",
    "    \t\t'-8 hours',\t    -- just to be sure pad by a bunch\n",
    "    \t\t'localtime'\t    -- dates in the sierra db are stored with gmt offset\n",
    "    \t) as lastupdate\n",
    "    FROM\n",
    "    \tjson_changes\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor_sqlite.execute(sql)\n",
    "        result = cursor_sqlite.fetchone()\n",
    "        if (\n",
    "            len(result) == 1\n",
    "            and result[0] is not None\n",
    "        ):\n",
    "            latest_update = str(result[0])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    print(latest_update, '\\n')\n",
    "    \n",
    "    with open('./sierra_patron_data.sql') as f:\n",
    "        cursor.execute(f.read(), (latest_update,))\n",
    "\n",
    "    with open('./output.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        i = 0\n",
    "        while(data:=cursor.fetchmany(1000)):\n",
    "            if i==0:\n",
    "                columns = [col[0] for col in cursor.description]\n",
    "                writer.writerow(columns)\n",
    "    \n",
    "            # write the data to a csv\n",
    "            writer.writerows(data)\n",
    "\n",
    "            # insert the appropriate data into each local sqlite table\n",
    "            \n",
    "            # patrons table\n",
    "            con_sqlite.executemany(\n",
    "                sql_patron_insert, \n",
    "                (\n",
    "                    (\n",
    "                        row[columns.index('patron_record_id')],\n",
    "                        row[columns.index('patron_record_num')],\n",
    "                        row[columns.index('campus_code')],\n",
    "                        row[columns.index('barcode1')],\n",
    "                        row[columns.index('home_library_code')],\n",
    "                        row[columns.index('ptype_code')],\n",
    "                        row[columns.index('create_date')],\n",
    "                        row[columns.index('delete_date')],\n",
    "                        row[columns.index('update_date')],\n",
    "                        row[columns.index('expire_date')],\n",
    "                        row[columns.index('active_date')],\n",
    "                        row[columns.index('claims_returned_total')],\n",
    "                        row[columns.index('owed_amt_cents')],\n",
    "                        row[columns.index('mblock_code')],\n",
    "                        row[columns.index('highest_level_overdue_num')],\n",
    "                        row[columns.index('num_revisions')],\n",
    "                    )\n",
    "                    for row in data\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # patron_address_json table\n",
    "            con_sqlite.executemany(\n",
    "                sql_address_json_insert, \n",
    "                (\n",
    "                    (\n",
    "                        row[columns.index('patron_record_id')],\n",
    "                        str(row[columns.index('patron_address_json')]),\n",
    "                    )\n",
    "                    for row in data\n",
    "                )\n",
    "            )\n",
    "\n",
    "            \n",
    "    \n",
    "            i+=1\n",
    "            print('.', end='')\n",
    "            # break\n",
    "        \n",
    "    print('done. ', i)\n",
    "    con_sqlite.commit()\n",
    "    cursor_sqlite.close()\n",
    "    cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
